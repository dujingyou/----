{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分 划分词频\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 读取《红楼梦》的文本数据，使用codecs包，它可以先通过设置文件的编码，对文件进行读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "file = codecs.open(\"HLM.txt\", 'r', 'utf-8')\n",
    "content = file.read()\n",
    "file.close()\n",
    "#print content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 引用jieba分词, 添加自定义词典\n",
    "\n",
    "jieba.load_userdict(file_name) # file_name为自定义词典的路径\n",
    "示例：\n",
    "云计算 \n",
    "李小福 \n",
    "创新办 \n",
    "之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 / \n",
    "加载自定义词库后： 李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 / \n",
    "\"通过用户自定义词典来增强歧义纠错能力\" --- https://github.com/fxsjy/jieba/issues/14\n",
    "\n",
    "import simplejson\n",
    "print simplejson.dumps(dict, encoding=\"UTF-8\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*- \n",
    "import jieba\n",
    "#import simplejson\n",
    "jieba.load_userdict(\"HLMwords.txt\")\n",
    "segments = []\n",
    "segs = jieba.cut(content)\n",
    "for seg in segs:\n",
    "    if len(seg)>1:\n",
    "        segments.append(seg)\n",
    "#print segments\n",
    "#print simplejson.dumps(segments, encoding=\"UTF-8\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 引入pandas（依赖于numpy）的 DataFrame（数据框）  DataFrame 是一个表格型的数据结构\n",
    "    A   B   C   .   .\n",
    "1   3   4   5   2   3\n",
    "2   1   2   3   2   5\n",
    "3   4   2   1   6   3\n",
    ".   3   3   2   2   3\n",
    ".   2   2   3   3   2\n",
    ".   1   2   4   3   1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95bfe5ad8431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[1;34m'year'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2002\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2002\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         'pop':[1.5,1.7,3.6,2.4,2.9]}\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "示例：\n",
    ">>> data = {'state':['Ohino','Ohino','Ohino','Nevada','Nevada'],\n",
    "        'year':[2000,2001,2002,2001,2002],\n",
    "        'pop':[1.5,1.7,3.6,2.4,2.9]}\n",
    ">>> df = DataFrame(data)\n",
    ">>> df\n",
    "   pop   state  year\n",
    "0  1.5   Ohino  2000\n",
    "1  1.7   Ohino  2001\n",
    "2  3.6   Ohino  2002\n",
    "3  2.4  Nevada  2001\n",
    "4  2.9  Nevada  2002\n",
    "\n",
    "[5 rows x 3 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "segmentDF = pandas.DataFrame({'segment':segments})\n",
    "#print segmentDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = pandas.read_csv(u\"StopwordsCN.txt\",encoding='utf-8',index_col=False,quoting=3,sep=\"\\t\",names=['stopword'])\n",
    "segmentDF = segmentDF[~segmentDF.segment.isin(stopwords.stopword)]\n",
    "#print segmentDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "stopwords = pandas.read_table(u\"StopwordsCN.txt\",encoding='utf-8',index_col=False,quoting=3,sep=\"\\t\",names=['stopword'])\n",
    "segmentDF = segmentDF[~segmentDF.segment.isin(stopwords.stopword)]\n",
    "wyStopWords = pandas.Series([\n",
    "\t\t  # 42 个文言虚词 \n",
    "\t\t  '之', '其', '或', '亦', '方', '于', '即', '皆', '因', '仍', '故', \n",
    "\t\t  '尚', '呢', '了', '的', '着', '一', '不', '乃', '呀', '吗', '咧', \n",
    "\t\t  '啊', '把', '让', '向', '往', '是', '在', '越', '再', '更', '比', \n",
    "\t\t  '很', '偏', '别', '好', '可', '便', '就', '但', '儿', \n",
    "\t\t  # 高频副词 \n",
    "\t\t  '又', '也', '都', '要', \n",
    "\t\t  # 高频代词 \n",
    "\t\t  '这', '那', '你', '我', '他',\n",
    "\t\t  #高频动词\n",
    "\t\t  '来', '去', '道', '笑', '说',\n",
    "\t\t  #空格\n",
    "\t\t  ' ', '','\\r\\n'\n",
    "\t\t]);\n",
    "segmentDF = segmentDF[~segmentDF.segment.isin(wyStopWords)]\n",
    "\n",
    "# pandas聚合和分组运算\n",
    "segStat = segmentDF.groupby(by=[\"segment\"])[\"segment\"].agg({\"计数\":numpy.size}).reset_index().sort_values(by=[\"计数\"],ascending=False);\n",
    "\t\t\t\n",
    "\n",
    "#print segStat.head(42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
